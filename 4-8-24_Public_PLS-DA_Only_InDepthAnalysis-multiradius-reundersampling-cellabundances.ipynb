{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f749d9d1-dde8-44c7-8c83-a6ce77e69f9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Objective: To run PLS-DA analysis on Vectra Halo Object data with Spatial Neighbors defined as Features \n",
    "\n",
    "Input: Object data with neighborhood profiles as a part of the dataframe.\n",
    "\n",
    "Output: PLS-DA plots, VIP scores, confusion matrices, ROC curve, permutation testing results, under-sampling results.\n",
    "\n",
    "\n",
    "Date most recent version: 11/4/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2c438-8477-4f4f-9a4e-f4c16f030616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pyopls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1084ca8d-1e67-426c-8473-a933b4d0f501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_623168/4059074071.py:20: DtypeWarning: Columns (9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,30,31,32,33,34,35,36,37,38,55,56,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  neighborData = pd.read_csv(location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985863\n",
      "0          1\n",
      "1          1\n",
      "2          1\n",
      "3          1\n",
      "4          1\n",
      "          ..\n",
      "1985858    1\n",
      "1985859    1\n",
      "1985860    1\n",
      "1985861    1\n",
      "1985862    1\n",
      "Name: ClassifierLabel_bin, Length: 1985863, dtype: object\n",
      "['PanCyto+MHCI+_tumor', 'PanCyto+MHCI+_stroma', 'PanCyto+MHCI-_tumor', 'PanCyto+MHCI-_stroma', 'CD8-CD3+IFNy+_tumor', 'CD8-CD3+IFNy+_stroma', 'CD8-CD3+IFNy-_tumor', 'CD8-CD3+IFNy-_stroma', 'CD8+CD3+IFNy+_tumor', 'CD8+CD3+IFNy+_stroma', 'CD8+CD3+IFNy-_tumor', 'CD8+CD3+IFNy-_stroma', 'CD56+CD3-IFNy+_tumor', 'CD56+CD3-IFNy+_stroma', 'CD56+CD3-IFNy-_tumor', 'CD56+CD3-IFNy-_stroma']\n",
      "['PanCyto+MHCI+_tumor Neighbors', 'PanCyto+MHCI+_stroma Neighbors', 'PanCyto+MHCI-_tumor Neighbors', 'PanCyto+MHCI-_stroma Neighbors', 'CD8-CD3+IFNy+_tumor Neighbors', 'CD8-CD3+IFNy+_stroma Neighbors', 'CD8-CD3+IFNy-_tumor Neighbors', 'CD8-CD3+IFNy-_stroma Neighbors', 'CD8+CD3+IFNy+_tumor Neighbors', 'CD8+CD3+IFNy+_stroma Neighbors', 'CD8+CD3+IFNy-_tumor Neighbors', 'CD8+CD3+IFNy-_stroma Neighbors', 'CD56+CD3-IFNy+_tumor Neighbors', 'CD56+CD3-IFNy+_stroma Neighbors', 'CD56+CD3-IFNy-_tumor Neighbors', 'CD56+CD3-IFNy-_stroma Neighbors']\n",
      "['Adenocarcinoma' nan 'Keratinizing SCC' 'Squamous Cell Carcinoma'\n",
      " 'Lepidic Adenocarcinoma' 'Acinar Adenocarcinoma'\n",
      " 'Papillary Adenocarcinoma' 'Mucinous Adenocarcinoma'\n",
      " 'Non-keratinizing SCC']\n",
      "cellNeighbors ['PanCyto+MHCI+_tumor Neighbors_30um', 'PanCyto+MHCI+_tumor Neighbors_200um', 'PanCyto+MHCI+_stroma Neighbors_30um', 'PanCyto+MHCI+_stroma Neighbors_200um', 'PanCyto+MHCI-_tumor Neighbors_30um', 'PanCyto+MHCI-_tumor Neighbors_200um', 'PanCyto+MHCI-_stroma Neighbors_30um', 'PanCyto+MHCI-_stroma Neighbors_200um', 'CD8-CD3+IFNy+_tumor Neighbors_30um', 'CD8-CD3+IFNy+_tumor Neighbors_200um', 'CD8-CD3+IFNy+_stroma Neighbors_30um', 'CD8-CD3+IFNy+_stroma Neighbors_200um', 'CD8-CD3+IFNy-_tumor Neighbors_30um', 'CD8-CD3+IFNy-_tumor Neighbors_200um', 'CD8-CD3+IFNy-_stroma Neighbors_30um', 'CD8-CD3+IFNy-_stroma Neighbors_200um', 'CD8+CD3+IFNy+_tumor Neighbors_30um', 'CD8+CD3+IFNy+_tumor Neighbors_200um', 'CD8+CD3+IFNy+_stroma Neighbors_30um', 'CD8+CD3+IFNy+_stroma Neighbors_200um', 'CD8+CD3+IFNy-_tumor Neighbors_30um', 'CD8+CD3+IFNy-_tumor Neighbors_200um', 'CD8+CD3+IFNy-_stroma Neighbors_30um', 'CD8+CD3+IFNy-_stroma Neighbors_200um', 'CD56+CD3-IFNy+_tumor Neighbors_30um', 'CD56+CD3-IFNy+_tumor Neighbors_200um', 'CD56+CD3-IFNy+_stroma Neighbors_30um', 'CD56+CD3-IFNy+_stroma Neighbors_200um', 'CD56+CD3-IFNy-_tumor Neighbors_30um', 'CD56+CD3-IFNy-_tumor Neighbors_200um', 'CD56+CD3-IFNy-_stroma Neighbors_30um', 'CD56+CD3-IFNy-_stroma Neighbors_200um']\n",
      "neighborData.columns Index(['Unnamed: 0.2', 'Unnamed: 0.1', 'Slide Index', 'Unnamed: 0',\n",
      "       'ImageLocation', 'XMin', 'XMax', 'YMin', 'YMax', 'CD8+IFNy+',\n",
      "       ...\n",
      "       'CD56+CD3-IFNy+_tumor Neighbors_200um',\n",
      "       'CD56+CD3-IFNy+_stroma Neighbors_200um',\n",
      "       'CD56+CD3-IFNy-_tumor Neighbors_200um',\n",
      "       'CD56+CD3-IFNy-_stroma Neighbors_200um', 'ImmuneCell', 'Stage',\n",
      "       'Differentiation', 'Histologic Type', 'AdvancedStage', 'Histology'],\n",
      "      dtype='object', length=114)\n",
      " abundance of centerCells 285766\n",
      "444\n",
      "109\n",
      "[(0.9921568627450981, 0.7019607843137254, 0.2196078431372549), (0.00784313725490196, 0.3176470588235294, 0.5882352941176471)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "439    0\n",
      "440    0\n",
      "441    0\n",
      "442    0\n",
      "443    0\n",
      "Name: Histology, Length: 444, dtype: int64\n",
      "                                         ImageLocation  PanCyto+MHCI+_tumor  \\\n",
      "34   E:\\Brown 3.21.19\\IMAGES 3.25.19\\MAD15-517_[419...                 76.0   \n",
      "188  E:\\Brown 4.25.19\\Unmixed Images 4.29.19\\MAD15-...                 35.0   \n",
      "132  E:\\Brown 3.21.19\\IMAGES 3.25.19\\MAD17-205_[509...                  0.0   \n",
      "282  E:\\Brown 4.25.19\\Unmixed Images 4.29.19\\MAD17-...                515.0   \n",
      "66   E:\\Brown 3.21.19\\IMAGES 3.25.19\\MAD15-690_[499...                120.0   \n",
      "..                                                 ...                  ...   \n",
      "386  E:\\Brown 4.25.19\\Unmixed Images 4.29.19\\MAD17-...                314.0   \n",
      "387  E:\\Brown 4.25.19\\Unmixed Images 4.29.19\\MAD17-...               1190.0   \n",
      "388  E:\\Brown 4.25.19\\Unmixed Images 4.29.19\\MAD17-...                216.0   \n",
      "389  E:\\Brown 4.25.19\\Unmixed Images 4.29.19\\MAD17-...                695.0   \n",
      "390  E:\\Brown 4.25.19\\Unmixed Images 4.29.19\\MAD17-...                 29.0   \n",
      "\n",
      "     PanCyto+MHCI+_stroma  PanCyto+MHCI-_tumor  PanCyto+MHCI-_stroma  \\\n",
      "34                    5.0               1700.0                  10.0   \n",
      "188                   7.0               1988.0                  10.0   \n",
      "132                   4.0                  7.0                   1.0   \n",
      "282                  88.0               4909.0                   6.0   \n",
      "66                   23.0                209.0                  44.0   \n",
      "..                    ...                  ...                   ...   \n",
      "386                  60.0                271.0                   3.0   \n",
      "387                  94.0               4921.0                   6.0   \n",
      "388                  36.0                388.0                   0.0   \n",
      "389                  92.0               3945.0                  21.0   \n",
      "390                   0.0                176.0                   0.0   \n",
      "\n",
      "     CD8-CD3+IFNy+_tumor  CD8-CD3+IFNy+_stroma  CD8-CD3+IFNy-_tumor  \\\n",
      "34                   0.0                   0.0                146.0   \n",
      "188                  0.0                   0.0                 11.0   \n",
      "132                  0.0                   0.0                  1.0   \n",
      "282                  0.0                   0.0                197.0   \n",
      "66                   0.0                   0.0                 38.0   \n",
      "..                   ...                   ...                  ...   \n",
      "386                  3.0                   0.0                 51.0   \n",
      "387                  1.0                   0.0                361.0   \n",
      "388                  0.0                   0.0                 66.0   \n",
      "389                  2.0                   0.0                106.0   \n",
      "390                  0.0                   0.0                  1.0   \n",
      "\n",
      "     CD8-CD3+IFNy-_stroma  CD8+CD3+IFNy+_tumor  CD8+CD3+IFNy+_stroma  \\\n",
      "34                 3666.0                  0.0                   0.0   \n",
      "188                  32.0                  0.0                   0.0   \n",
      "132                  32.0                  0.0                   0.0   \n",
      "282                 218.0                  0.0                   0.0   \n",
      "66                   27.0                  0.0                   0.0   \n",
      "..                    ...                  ...                   ...   \n",
      "386                 125.0                  2.0                   0.0   \n",
      "387                 492.0                  6.0                   0.0   \n",
      "388                  91.0                  1.0                   1.0   \n",
      "389                 156.0                  0.0                   0.0   \n",
      "390                   0.0                  0.0                   0.0   \n",
      "\n",
      "     CD8+CD3+IFNy-_tumor  CD8+CD3+IFNy-_stroma  CD56+CD3-IFNy+_tumor  \\\n",
      "34                  93.0                 855.0                   0.0   \n",
      "188                  1.0                   3.0                   5.0   \n",
      "132                  2.0                  13.0                   0.0   \n",
      "282                 18.0                  21.0                   1.0   \n",
      "66                  22.0                   7.0                   0.0   \n",
      "..                   ...                   ...                   ...   \n",
      "386                 12.0                  17.0                   0.0   \n",
      "387                419.0                 421.0                   0.0   \n",
      "388                 47.0                  65.0                   0.0   \n",
      "389                 70.0                 103.0                   0.0   \n",
      "390                  0.0                   0.0                   0.0   \n",
      "\n",
      "     CD56+CD3-IFNy+_stroma  CD56+CD3-IFNy-_tumor  CD56+CD3-IFNy-_stroma  \\\n",
      "34                     0.0                   2.0                  116.0   \n",
      "188                    3.0                  69.0                   24.0   \n",
      "132                    0.0                   0.0                    0.0   \n",
      "282                    1.0                  21.0                    1.0   \n",
      "66                     0.0                   1.0                    0.0   \n",
      "..                     ...                   ...                    ...   \n",
      "386                    0.0                   2.0                    0.0   \n",
      "387                    0.0                  12.0                    0.0   \n",
      "388                    0.0                   1.0                    0.0   \n",
      "389                    0.0                   1.0                    1.0   \n",
      "390                    0.0                   0.0                    0.0   \n",
      "\n",
      "     Histology  \n",
      "34           0  \n",
      "188          0  \n",
      "132          0  \n",
      "282          0  \n",
      "66           0  \n",
      "..         ...  \n",
      "386          1  \n",
      "387          1  \n",
      "388          1  \n",
      "389          1  \n",
      "390          1  \n",
      "\n",
      "[218 rows x 18 columns]\n",
      "444\n",
      "   PatientID  NumSlides  Histology\n",
      "0     15-513          7          0\n",
      "1     15-517         35          0\n",
      "2     15-623         21          0\n",
      "3     15-645         14          0\n",
      "4     15-651         11          0\n",
      "5     15-690         15          0\n",
      "6     16-078         16          1\n",
      "7     16-099         11          0\n",
      "8     16-101         31          1\n",
      "9     16-180         26          0\n",
      "10    16-196          6          0\n",
      "11    17-071          7          1\n",
      "12    17-091         13          0\n",
      "13    17-194         23          0\n",
      "14    17-205         17          0\n",
      "15    17-249         17          0\n",
      "16    17-303          8          0\n",
      "17    17-306          5          0\n",
      "18    17-351         11          1\n",
      "19    17-356         23          1\n",
      "20    17-365         15          0\n",
      "21    17-392         10          0\n",
      "22    17-395         19          0\n",
      "23    17-416          9          0\n",
      "24    17-445         12          1\n",
      "25    17-450          7          0\n",
      "26    17-507         14          0\n",
      "27    17-510          9          1\n",
      "28    17-514          4          0\n",
      "29    17-524          5          0\n",
      "30    17-536         15          0\n",
      "31    17-549          8          0\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.io\n",
    "from pyopls import OPLS\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# File paths\n",
    "neighbor_data_path = '/scratch/kag7stn/Brown 11-12-23 Neighbor Finding Codes/5-9-24-BrownData_neighbors_multiradius_merged_scc_adeno.csv'\n",
    "stage_data_path = '/scratch/kag7stn/Brown_NSCLC_StageData.xlsx'\n",
    "\n",
    "# Analysis settings\n",
    "study_name = 'Brown_NSCLC_allradius_30um'\n",
    "date = '4-21-24'\n",
    "stagesort, histologysort, regionsort = False, False, False\n",
    "undersampled, orthogonalized, conditionalNeighbor, multiradius = True, True, False, True\n",
    "\n",
    "# Loading and preparing data\n",
    "neighborData = pd.read_csv(neighbor_data_path).iloc[:-100]  # Exclude last 100 rows\n",
    "stageData = pd.read_excel(stage_data_path)\n",
    "print(f\"Initial neighbor data length: {len(neighborData)}\")\n",
    "\n",
    "# Renaming columns in stage data\n",
    "stageData = stageData.rename(columns={'Patient': 'PatientID', 'Differntiation': 'Differentiation'})\n",
    "\n",
    "# Define cell types for analysis\n",
    "cellTypes = ['PanCyto+MHCI+', 'PanCyto+MHCI-', 'CD8-CD3+IFNy+', 'CD8-CD3+IFNy-', 'CD8+CD3+IFNy+', 'CD8+CD3+IFNy-', 'CD56+CD3-IFNy+', 'CD56+CD3-IFNy-']\n",
    "cellTypes_classifier = [f\"{cell}_tumor\" for cell in cellTypes] + [f\"{cell}_stroma\" for cell in cellTypes]\n",
    "cellNeighbors = [f\"{cell} Neighbors\" for cell in cellTypes_classifier]\n",
    "\n",
    "# Handling multiradius columns\n",
    "if multiradius:\n",
    "    cellNeighbors = [f\"{col}_30um\" for col in cellNeighbors] + [f\"{col}_200um\" for col in cellNeighbors]\n",
    "\n",
    "# Merging metadata\n",
    "neighborData = neighborData.merge(stageData[['PatientID', 'Stage', 'Differentiation', 'Histologic Type']], on='PatientID', how='left')\n",
    "\n",
    "# Helper functions for data labeling\n",
    "def get_advanced_stage(stage):\n",
    "    stage = str(stage)\n",
    "    if stage.startswith(\"G2\") or stage.startswith(\"G3\") or stage.startswith(\"G4\"):\n",
    "        return 1\n",
    "    elif stage.startswith(\"G1\"):\n",
    "        return 0\n",
    "    return None\n",
    "\n",
    "def get_histology(stage):\n",
    "    stage = str(stage)\n",
    "    if any(sub in stage for sub in [\"Keratinizing\", \"Non\", \"Squam\"]):\n",
    "        return 1\n",
    "    elif any(sub in stage for sub in [\"Adenocarcinoma\", \"Lepidic\", \"Acinar\", \"Papillary\", \"Mucinous\"]):\n",
    "        return 0\n",
    "    return None\n",
    "\n",
    "# Applying classification\n",
    "neighborData['AdvancedStage'] = neighborData[\"Stage\"].apply(get_advanced_stage)\n",
    "neighborData['Histology'] = neighborData['Histologic Type'].apply(get_histology)\n",
    "neighborData = neighborData.dropna(subset=['AdvancedStage', 'Histology'])\n",
    "\n",
    "# Filtering data by analysis settings\n",
    "if stagesort:\n",
    "    neighborData = neighborData[neighborData['AdvancedStage'] == 1]\n",
    "if histologysort:\n",
    "    neighborData = neighborData[neighborData['Histology'] == 0]\n",
    "if regionsort:\n",
    "    neighborData = neighborData[neighborData['ClassifierLabel_bin'] == 0]\n",
    "\n",
    "# Defining analysis parameters\n",
    "centerCell = ['PanCyto+MHCI+']\n",
    "classifier = ['Histology']\n",
    "print(f\"cellNeighbors: {cellNeighbors}\")\n",
    "print(f\"neighborData columns: {neighborData.columns}\")\n",
    "\n",
    "# Isolate center cells\n",
    "centerCells = neighborData[neighborData[centerCell[0]] == 1]\n",
    "print(f\"Abundance of center cells: {len(centerCells)}\")\n",
    "\n",
    "# Grouping and merging histology data\n",
    "grouped_df = neighborData.groupby('ImageLocation')[cellTypes].sum().reset_index()\n",
    "histology_mapping = neighborData.groupby('ImageLocation')['Histology'].first().reset_index()\n",
    "xData = pd.merge(grouped_df, histology_mapping, on='ImageLocation')\n",
    "\n",
    "# Plotting proportions of classifier labels\n",
    "proportions = [\n",
    "    len(xData[xData[classifier[0]] == 1]) / len(xData),\n",
    "    len(xData[xData[classifier[0]] == 0]) / len(xData)\n",
    "]\n",
    "colors = [(253/255, 179/255, 56/255), (2/255, 81/255, 150/255)]\n",
    "plt.pie(proportions, colors=colors, startangle=90, \n",
    "        autopct=lambda p: '{:.0f}\\n{:.1f}%'.format(p * len(xData) / 100, p),\n",
    "        textprops={'color': 'white', 'fontsize': 20})\n",
    "plt.title(f\"Proportion of {centerCell[0]} Cells with {classifier[0]} Status\")\n",
    "plt.savefig(f\"{date}{study_name}{centerCell[0]}{classifier[0]}_proportions_piechart_labeled.pdf\", format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Undersampling to balance classes\n",
    "X, y = xData, xData[classifier[0]].astype(int)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "print(f\"Resampled data: {len(X_resampled)} rows\")\n",
    "\n",
    "# Grouping slide counts and histology info by PatientID\n",
    "slide_counts = neighborData.groupby('PatientID')['ImageLocation'].nunique().reset_index()\n",
    "histology_info = neighborData.groupby('PatientID')['Histology'].first().reset_index()\n",
    "slide_counts = pd.merge(slide_counts, histology_info, on='PatientID')\n",
    "slide_counts.columns = ['PatientID', 'NumSlides', 'Histology']\n",
    "print(slide_counts)\n",
    "\n",
    "# Saving the modified xData to a CSV file\n",
    "xData.to_csv(\"/scratch/kag7stn/5-9-24-BrownData_neighbors_multiradius_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e8235-11a6-4e9b-bfbf-4b46ad29ba59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar plot for unique PatientIDs\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=unique_patient_counts.index, y=unique_patient_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Number of Unique PatientIDs within Each Histology Group\")\n",
    "plt.xlabel(\"Histology Group\")\n",
    "plt.ylabel(\"Number of Unique PatientIDs\")\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for unique ImageLocation names\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=unique_image_location_counts.index, y=unique_image_location_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Number of Unique ImageLocation Names within Each Histology Group\")\n",
    "plt.xlabel(\"Histology Group\")\n",
    "plt.ylabel(\"Number of Unique ImageLocation Names\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e40a4-a25b-4467-905c-784972504d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting up the figure size for better visualization\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.pie(\n",
    "    patients,                # Data values\n",
    "    labels=grades,           # Labels for each section\n",
    "    autopct='%1.1f%%',       # Display percentage on each section\n",
    "    startangle=140           # Rotate the chart to start from a specified angle\n",
    ")\n",
    "\n",
    "# Ensuring the pie chart is circular\n",
    "plt.axis('equal')\n",
    "\n",
    "# Adding a title\n",
    "plt.title('Distribution of Patients by Grade')\n",
    "\n",
    "# Displaying the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781d04d-ba3b-46be-ae82-85432d73c037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Function to create box plots for MHCI- and MHCI+ data\n",
    "def create_box_plot(ax, data_minus, data_plus, label_minus, label_plus, color_minus, color_plus, position):\n",
    "    # Box plot for MHCI- data\n",
    "    ax.boxplot(data_minus, positions=[position], widths=1,\n",
    "               boxprops=dict(alpha=0.5, color='black', linewidth=2), showfliers=False)\n",
    "\n",
    "    # Box plot for MHCI+ data\n",
    "    ax.boxplot(data_plus, positions=[position + 1], widths=1,\n",
    "               boxprops=dict(alpha=0.5, color='black', linewidth=2), showfliers=False)\n",
    "\n",
    "    # Setting y-axis label\n",
    "    ax.set_ylabel(\"Number of Neighbors\", fontsize=20)\n",
    "\n",
    "# Function to create swarm plots for MHCI- and MHCI+ data\n",
    "def create_swarm_plot(ax, data_minus, data_plus, color_minus, color_plus, positions):\n",
    "    sns.swarmplot(x=positions[0] - 0.2, y=data_minus, ax=ax, color=color_minus, size=5)\n",
    "    sns.swarmplot(x=positions[1] + 0.2, y=data_plus, ax=ax, color=color_plus, size=5)\n",
    "\n",
    "# Data preparation (example assumes `xData`, `classifier`, `centerCell`, `cellNeighbors`, etc., are defined)\n",
    "mhci_plus_df = xData[xData[classifier[0]] == 1]\n",
    "mhci_minus_df = xData[xData[classifier[0]] == 0]\n",
    "\n",
    "# Initialize plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# Define positions for the boxplots\n",
    "positions = range(len(cellNeighbors))\n",
    "\n",
    "# Loop through each feature for pairwise comparisons and plotting\n",
    "for i, column in enumerate(cellNeighbors):\n",
    "    # Data selection for MHCI+ and MHCI- groups\n",
    "    mhci_minus_data = mhci_minus_df[column].values\n",
    "    mhci_plus_data = mhci_plus_df[column].values\n",
    "    \n",
    "    # Perform Mann-Whitney U test\n",
    "    t_stat, p_value = stats.mannwhitneyu(mhci_minus_data, mhci_plus_data, alternative='two-sided')\n",
    "    \n",
    "    # Create box plots at specific positions\n",
    "    create_box_plot(ax, mhci_minus_data, mhci_plus_data,\n",
    "                    f'{classifier[0]}- {centerCell[0]}', f'{classifier[0]}+ {centerCell[0]}',\n",
    "                    blue_rgb, yellow_rgb, position=positions[i]*2)\n",
    "    \n",
    "    # Sample data for swarm plot\n",
    "    mhci_minus_data = mhci_minus_df[column].sample(n=13, random_state=42)\n",
    "    mhci_plus_data = mhci_plus_df[column].sample(n=13, random_state=42)\n",
    "    \n",
    "    # Determine direction of difference and calculate log p-value\n",
    "    log_p_value = np.log1p(p_value)\n",
    "    direction = '-' if np.median(mhci_minus_data) > np.median(mhci_plus_data) else '+'\n",
    "    \n",
    "    # Annotate plot with p-value\n",
    "    ax.text(positions[i]*2 + 0.5, max(max(mhci_minus_data), max(mhci_plus_data)) + 0.5,\n",
    "            f'{direction} {p_value:.2e}', ha='center', va='bottom', fontsize=14, color='black')\n",
    "    \n",
    "    # Create swarm plot\n",
    "    create_swarm_plot(ax, mhci_minus_data, mhci_plus_data, blue_rgb, yellow_rgb,\n",
    "                      positions=[positions[i] - 0.2, positions[i] + 0.2])\n",
    "\n",
    "# Customize x-ticks\n",
    "positions = [2 * pos + 0.5 for pos in range(len(cellNeighbors))]\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels([f'{column}' for column in cellNeighbors], rotation=45, ha='right', fontsize=20)\n",
    "\n",
    "# Adjust layout and save figure\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.savefig(f\"{date}{studyname}Brown_{centerCell[0]}{classifier[0]}_SampledCellNeighbors_boxplot.pdf\",\n",
    "            format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5fba8-3d9e-4517-ad15-78bd97dc69e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute the shuffle test for mean differences\n",
    "def shuffle_test_mean_diff(ax, mhci_minus_data, mhci_plus_data, num_shuffles=100):\n",
    "    # Combine data from MHCI- and MHCI+ groups\n",
    "    combined_data = np.concatenate([mhci_minus_data, mhci_plus_data])\n",
    "    \n",
    "    # Calculate the observed difference in means\n",
    "    observed_diff_means = np.mean(mhci_minus_data) - np.mean(mhci_plus_data)\n",
    "    \n",
    "    # Shuffle the data and compute the difference in means for each shuffle\n",
    "    shuffled_diff_means = []\n",
    "    for _ in range(num_shuffles):\n",
    "        np.random.shuffle(combined_data)\n",
    "        shuffled_data_minus = combined_data[:len(mhci_minus_data)]\n",
    "        shuffled_data_plus = combined_data[len(mhci_minus_data):]\n",
    "        shuffled_diff_means.append(np.mean(shuffled_data_minus) - np.mean(shuffled_data_plus))\n",
    "    \n",
    "    # Calculate the p-value by comparing shuffled differences to the observed difference\n",
    "    p_value = np.mean(np.array(shuffled_diff_means) >= observed_diff_means)\n",
    "    \n",
    "    # Perform a t-test on the shuffled differences in means\n",
    "    t_stat, p_value_shuffle = stats.ttest_1samp(shuffled_diff_means, observed_diff_means)\n",
    "    \n",
    "    # Plot histogram of shuffled differences in means\n",
    "    sns.histplot(shuffled_diff_means, bins=20, kde=True, color='skyblue', alpha=0.7, label='Shuffled Differences in Means', ax=ax)\n",
    "    ax.axvline(x=observed_diff_means, color='red', linestyle='--', label='Observed Difference in Means')\n",
    "    ax.set_xlabel('Difference in Means')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Distribution of Shuffled Differences in Means')\n",
    "    ax.legend()\n",
    "\n",
    "    # Print results\n",
    "    print(\"Observed difference in means:\", observed_diff_means)\n",
    "    print(\"P-value (shuffling test):\", p_value)\n",
    "    print(\"P-value (t-test on shuffled differences):\", p_value_shuffle)\n",
    "\n",
    "# Example usage with data for each column in `cellNeighbors`\n",
    "for i, column in enumerate(cellNeighbors):\n",
    "    # Sampling 100 data points from each group\n",
    "    mhci_minus_data = mhci_minus_df[column].sample(n=100, random_state=42)\n",
    "    mhci_plus_data = mhci_plus_df[column].sample(n=100, random_state=42)\n",
    "    \n",
    "    # Create a new plot for each feature\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Perform the shuffle test and plot results\n",
    "    shuffle_test_mean_diff(ax, mhci_minus_data, mhci_plus_data, num_shuffles=100)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8e18f-2ee8-4d51-82a6-4fb2ebd21e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Significance level mapping\n",
    "def get_significance_symbol(p_value):\n",
    "    if p_value < 1e-6:\n",
    "        return '***'\n",
    "    elif p_value < 0.001:\n",
    "        return '**'\n",
    "    elif p_value < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "# Helper functions for plot creation\n",
    "def create_box_plot(ax, data_minus, data_plus, position):\n",
    "    ax.boxplot(data_minus, positions=[position], widths=1, boxprops=dict(alpha=0.5, color='black', linewidth=2), showfliers=False)\n",
    "    ax.boxplot(data_plus, positions=[position + 1], widths=1, boxprops=dict(alpha=0.5, color='black', linewidth=2), showfliers=False)\n",
    "\n",
    "def create_swarm_plot(ax, data_minus, data_plus, color_minus, color_plus, position):\n",
    "    sns.swarmplot(x=position[0], y=data_minus, ax=ax, color=color_minus, size=6)\n",
    "    sns.swarmplot(x=position[1], y=data_plus, ax=ax, color=color_plus, size=6, marker='s')\n",
    "\n",
    "# Data selection\n",
    "mhci_plus_df = xData[xData[classifier[0]] == 1]\n",
    "mhci_minus_df = xData[xData[classifier[0]] == 0]\n",
    "\n",
    "# Columns and formatting\n",
    "columns_30um = [col for col in cellNeighbors if col.endswith('_30um')]\n",
    "columns_200um = [col for col in cellNeighbors if col.endswith('_200um')]\n",
    "formatted_columns = [col.split(' ')[0] for col in columns_30um]\n",
    "\n",
    "# Plot setup\n",
    "fig, axs = plt.subplots(2, 1, figsize=(18, 12))\n",
    "sns.set(style=\"ticks\", font_scale=1.6)\n",
    "distances = ['30 um', '200 um']\n",
    "y_scale = [3, 80]\n",
    "\n",
    "# Plotting each radius in subplots\n",
    "for k, (ax, columns) in enumerate(zip(axs, [columns_30um, columns_200um])):\n",
    "    positions = range(len(columns))\n",
    "    for i, column in enumerate(columns):\n",
    "        # Data and testing\n",
    "        data_minus, data_plus = mhci_minus_df[column].values, mhci_plus_df[column].values\n",
    "        _, p_value = stats.mannwhitneyu(data_minus, data_plus, alternative='two-sided')\n",
    "        _, p_adjusted, _, _ = multipletests([p_value], method='fdr_bh')\n",
    "        \n",
    "        # Plotting elements\n",
    "        create_box_plot(ax, data_minus, data_plus, position=positions[i] * 2)\n",
    "        create_swarm_plot(ax, data_minus, data_plus, blue_rgb, yellow_rgb, positions=[positions[i] - 0.2, positions[i] + 0.2])\n",
    "\n",
    "        # Annotation\n",
    "        y_pos = max(max(data_minus), max(data_plus)) + 0.5\n",
    "        ax.text(positions[i] * 2, y_pos + y_scale[k] * 0.5, '-' if np.mean(data_minus) > np.mean(data_plus) else '+', ha='center', fontsize=14)\n",
    "        ax.text(positions[i] * 2 + 0.5, y_pos + y_scale[k] * 0.05, get_significance_symbol(p_adjusted[0]), ha='center', fontsize=22)\n",
    "\n",
    "    # Axis labels and legend\n",
    "    ax.set_xticks([2 * pos + 0.5 for pos in range(len(columns))])\n",
    "    ax.set_xticklabels(formatted_columns, rotation=30, ha='right', fontsize=18)\n",
    "    ax.set_ylabel(f\"{distances[k]} radius\", fontsize=20)\n",
    "\n",
    "# Legend and title\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', label=f'{classifier[0]}-', markerfacecolor=blue_rgb, markersize=8),\n",
    "    Line2D([0], [0], marker='s', color='w', label=f'{classifier[0]}+', markerfacecolor=yellow_rgb, markersize=8)\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='best')\n",
    "plt.suptitle(f\"Comparing Neighborhood Profiles of {classifier[0]}- {centerCell[0]} and {classifier[0]}+ {centerCell[0]} Cells\", fontsize=24)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save and display\n",
    "plt.savefig(f'Brown_{centerCell[0]}{classifier[0]}_SampledCellNeighbors_boxplot_subplots.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6f202-7fbc-4a05-8f2a-5243c770697e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### This kernel iterates over the dataframe 1000 times and reundersamples it \n",
    "# It then performs the PLSDA on the under-sampled data, and average 5 fold cross validation accuracy can be displayed for each one \n",
    "# A distribution is shown as a histogram that displays the accuracy of each of the re-undersampled attempts (and average CV accuracy)\n",
    "# Input to kernel: xData (xData is not affected by this kernel)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Define the number of undersampling iterations\n",
    "n_iterations = 1000\n",
    "\n",
    "print(classifier[0])\n",
    "classifier_column =  classifier[0]  # Replace 'your_column_name' with the actual column name\n",
    "\n",
    "# Check if classifier_column is in xData columns\n",
    "if classifier_column in xData.columns:\n",
    "    # Print unique items\n",
    "    unique_items = xData[classifier_column].unique()\n",
    "    print(\"Unique items in xData[classifier_column]:\")\n",
    "    for item in unique_items:\n",
    "        print(item)\n",
    "\n",
    "\n",
    "# Initialize a list to store the accuracy results\n",
    "accuracy_results = []\n",
    "\n",
    "\n",
    "# Transform the Xdata, remove relevant columns, and then export it if you need to perform orthogonalization in Matlab\n",
    "import scipy.io\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "columns_to_drop_multiradius=[]\n",
    "#columns_to_drop = []#'PanCyto+MHCI+_tumor Neighbors', 'PanCyto+MHCI+_stroma Neighbors', 'PanCyto+MHCI-_tumor Neighbors', 'PanCyto+MHCI-_stroma Neighbors']\n",
    "\n",
    "# Assuming X_scaled and y are your variables\n",
    "if conditionalNeighbor==True :\n",
    "    columns_to_drop = [conditionalNeighborCellClassifier,conditionalNeighborCellClassifier_s]\n",
    "else:\n",
    "    columns_to_drop = []\n",
    "    #columns_to_drop = []\n",
    "for col in columns_to_drop:\n",
    "    columns_to_drop_multiradius.append(col + '_30um')\n",
    "    columns_to_drop_multiradius.append(col + '_200um')\n",
    "   # columns_to_drop_multiradius.append(col + '_30-200um')\n",
    "    \n",
    "X = xData[cellNeighbors] # Replace with your data loading code\n",
    "X= X.drop(columns = columns_to_drop_multiradius, axis=1)\n",
    "\n",
    "\n",
    "dimensions = X.shape\n",
    "\n",
    "print(\"Number of rows:\", dimensions[0])\n",
    "print(\"Number of columns:\", dimensions[1])\n",
    "\n",
    "\n",
    "cellNeighbors = [i for i in cellNeighbors  if i not in columns_to_drop_multiradius]\n",
    "\n",
    "#cellNeighbors = [col for col in cellNeighbors if not col.startswith('PanCyto+')]\n",
    "print(cellNeighbors)\n",
    "print(len(cellNeighbors))\n",
    "\n",
    "\n",
    "#X = xData[cellNeighbors] # Replace with your data loading code\n",
    "#X = X.loc[(X[cellNeighbors] != 0).any(axis=1)]\n",
    "\n",
    "X = np.log1p(X)\n",
    "\n",
    "y = xData[classifier[0]]\n",
    "\n",
    "print(y)\n",
    "print(y.dtype) \n",
    "y = pd.to_numeric(y,errors='coerce')\n",
    "print(y)\n",
    "\n",
    "#print(xData)\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X) \n",
    "\n",
    "\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Random Undersampling of our classes\n",
    "    rus = RandomUnderSampler(sampling_strategy='auto', random_state=None)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_scaled, y)\n",
    "\n",
    "    # Define the number of folds\n",
    "    n_folds = 5\n",
    "\n",
    "    # Calculate the size of each fold\n",
    "    fold_size = len(X_resampled) // n_folds\n",
    "\n",
    "    # Initialize variables to accumulate confusion matrix results\n",
    "    cumulative_conf_matrix = [[0, 0], [0, 0]]\n",
    "    cumulative_accuracy = 0\n",
    "\n",
    "    # Perform n_folds cross-validation\n",
    "    for i in range(n_folds):\n",
    "        # Determine the indices for this fold\n",
    "        start_idx = i * fold_size\n",
    "        end_idx = start_idx + fold_size\n",
    "\n",
    "        # Split the data into training and test sets for this fold\n",
    "        X_test = X_resampled[start_idx:end_idx]\n",
    "        y_test = y_resampled[start_idx:end_idx]\n",
    "      #  print('y_test')\n",
    "       # print(y_test)\n",
    "        X_train = np.concatenate([X_resampled[:start_idx], X_resampled[end_idx:]])\n",
    "        y_train = np.concatenate([y_resampled[:start_idx], y_resampled[end_idx:]])\n",
    "\n",
    "        # Create and fit the PLS-DA model\n",
    "        plsda = PLSRegression(n_components=2)\n",
    "        plsda.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = plsda.predict(X_test)\n",
    "\n",
    "        # Convert predictions to class labels\n",
    "        y_pred_labels = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "        # Accumulate confusion matrix results\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
    "        cumulative_conf_matrix += conf_matrix\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "        cumulative_accuracy += accuracy\n",
    "\n",
    "    # Calculate average accuracy across all folds for this iteration\n",
    "    average_accuracy = cumulative_accuracy / n_folds\n",
    "    accuracy_results.append(average_accuracy)\n",
    "\n",
    "# Calculate mean\n",
    "mean_value = np.mean(accuracy_results)\n",
    "\n",
    "# Calculate standard deviation\n",
    "std_deviation = np.std(accuracy_results)\n",
    "\n",
    "print(accuracy_results)\n",
    "# Plot the accuracy results as a histogram\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.set(font_scale = 1.0)\n",
    "sns.set_style(\"ticks\")\n",
    "plt.hist(accuracy_results, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f\"Under-sampling Accuracy (Avg:{mean_value:.2f}, Std:{std_deviation:.3f})\")\n",
    "plt.savefig(date + studyname + centerCell[0] + '_undersample_accuracy_dist .pdf', format='pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "    \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "if len(np.unique(y_test)) == 2:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_threshold = thresholds[np.argmax(youden_j)]\n",
    "    print(f'Optimal Threshold: {optimal_threshold}')\n",
    "else:\n",
    "    print(\"ROC curve and AUC calculation skipped due to lack of both classes in y_test.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb3e08-2da4-4f92-9320-7b446de3411f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform the Xdata, remove relevant columns, and then export it if you need to perform orthogonalization in Matlab\n",
    "import scipy.io\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Assuming X_scaled and y are your variables\n",
    "columns_to_drop = []\n",
    "    \n",
    "X = xData[cellTypes] # Replace with your data loading code\n",
    "#X= X.drop(columns = columns_to_drop_multiradius, axis=1)\n",
    "\n",
    "\n",
    "dimensions = X.shape\n",
    "\n",
    "print(\"Number of rows:\", dimensions[0])\n",
    "print(\"Number of columns:\", dimensions[1])\n",
    "print(cellNeighbors)\n",
    "print(len(cellNeighbors))\n",
    "\n",
    "X = np.log1p(X)\n",
    "y = xData[classifier[0]]\n",
    "y = pd.to_numeric(y,errors='coerce')\n",
    "print(y)\n",
    "X_scaled = StandardScaler().fit_transform(X) \n",
    "\n",
    "# Random Undersampling of our classes \n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=54)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_scaled, y)\n",
    "print(len(y))\n",
    "print(len(y_resampled))\n",
    "print(y_resampled.sum())\n",
    "\n",
    "# Create a dictionary to store the variables\n",
    "data = {\n",
    "    'X_scaled': X_resampled,\n",
    "    'y': y_resampled,\n",
    "}\n",
    "\n",
    "# Specify the file path where you want to save the .mat file\n",
    "mat_file_path = 'Brown' + centerCell[0] + classifier[0] + 'xData__neighbors_undersampled_v6.mat'\n",
    "\n",
    "# Save the variables to a .mat file\n",
    "scipy.io.savemat(mat_file_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9280f9-6ace-4da7-b405-9bfc5d699071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_score, confusion_matrix\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.utils import shuffle\n",
    "from pyopls import OPLS\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "\n",
    "if undersampled == True:\n",
    "    X = X_resampled\n",
    "    y = y_resampled\n",
    "    \n",
    "if orthogonalized == True: \n",
    "    opls = OPLS(2) # 1 components\n",
    "    X = opls.fit_transform(X, y)\n",
    "\n",
    "# Calculate the size of each fold\n",
    "fold_size = len(X) // n_folds\n",
    "\n",
    "# Initialize variables to accumulate confusion matrix results and x_scores/y_scores\n",
    "cumulative_conf_matrix = [[0, 0], [0, 0]]\n",
    "cumulative_accuracy = 0\n",
    "cumulative_x_scores = []\n",
    "cumulative_y_scores = []\n",
    "cumulative_y_test = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for i in range(n_folds):\n",
    "    # Determine the indices for this fold\n",
    "    start_idx = i * fold_size\n",
    "    end_idx = start_idx + fold_size\n",
    "\n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_test = X[start_idx:end_idx]\n",
    "    y_test = y[start_idx:end_idx]\n",
    "    #print(y_test)\n",
    "    #print(type(y_test))\n",
    "    X_train = np.concatenate([X[:start_idx], X[end_idx:]])\n",
    "    y_train = np.concatenate([y[:start_idx], y[end_idx:]])\n",
    "\n",
    "    # Create and fit the PLS-DA model\n",
    "    plsda = PLSRegression(n_components=2)\n",
    "    plsda.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = plsda.predict(X_test)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    y_pred_labels = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "    # Accumulate confusion matrix results\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
    "    cumulative_conf_matrix += conf_matrix\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "    cumulative_accuracy += accuracy\n",
    "\n",
    "    # Accumulate x_scores and y_scores\n",
    "    print(y_test)\n",
    "    cumulative_y_test.extend(y_test.tolist())\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "average_accuracy = cumulative_accuracy / n_folds\n",
    "#print(cumulative_y_test)\n",
    "# Calculate precision\n",
    "TP = cumulative_conf_matrix[1, 1]  # True Positives\n",
    "FP = cumulative_conf_matrix[0, 1]  # False Positives\n",
    "FN = cumulative_conf_matrix[1, 0]\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Confusion Matrix:\\n{cumulative_conf_matrix}\")\n",
    "\n",
    "# Display the heatmap\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.set_style(\"ticks\")\n",
    "sns.heatmap(cumulative_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title(f\"Confusion Matrix (F1 Score: {f1:.2f}, Precision: {precision:.2f})\")\n",
    "plt.savefig(date + studyname + centerCell[0] + '_confusionMatrix.pdf', format='pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63736120-72a7-490e-9841-8aff565cba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PLSDA Analysis and Plotting the Points onto the LV axes\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "lv1_scores = plsda.x_scores_[:, 0]  # LV1 scores\n",
    "lv2_scores = plsda.x_scores_[:, 1]  # LV2 scores\n",
    "print(len(lv1_scores))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Scale y_scores_ to [0, 1] using a sigmoid function\n",
    "y_scores_scaled = sigmoid(plsda.y_scores_)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the total variance of X and Y\n",
    "total_variance_x = np.var(X_train, axis=0).sum()\n",
    "total_variance_y = np.var(y_train, axis=0).sum()\n",
    "\n",
    "# Calculate the variance explained by each LV in X and Y\n",
    "variance_explained_x = plsda.x_scores_.var(axis=0)\n",
    "variance_explained_y = y_scores_scaled.var(axis=0)\n",
    "\n",
    "# Calculate the percentage of variance explained by each LV in X and Y\n",
    "pctvar_x = variance_explained_x / total_variance_x * 100\n",
    "pctvar_y = variance_explained_y / total_variance_y * 100\n",
    "\n",
    "print(\"Percentage of variance explained by each latent variable in X:\")\n",
    "print(pctvar_x)\n",
    "print(\"\\nPercentage of variance explained by each latent variable in Y:\")\n",
    "print(pctvar_y)\n",
    "\n",
    "\n",
    "total_variance_y = np.var(y_train, axis=0).sum()\n",
    "\n",
    "# Calculate the variance explained by each LV in Y\n",
    "variance_explained_y = plsda.y_scores_.var(axis=0)\n",
    "print('plsda.y_scores_')\n",
    "print(plsda.y_scores_)\n",
    "# Calculate the percentage of variance explained by each LV in Y\n",
    "pctvar_y = variance_explained_y / total_variance_y * 100\n",
    "\n",
    "print(\"Percentage of variance explained by each latent variable in Y:\")\n",
    "print(pctvar_y)\n",
    "\n",
    "\n",
    "yvals = y_train.squeeze()\n",
    "print(yvals)\n",
    "#print(type(yvals))\n",
    "\n",
    "\n",
    "num_samples = 13\n",
    "sample_indices = random.sample(range(len(lv1_scores)), num_samples)\n",
    "\n",
    "# # Select the scores corresponding to the random indices\n",
    "# sample_lv1_scores = lv1_scores[sample_indices]\n",
    "# sample_lv2_scores = lv2_scores[sample_indices]\n",
    "# sample_yvals = yvals.iloc[sample_indices]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.grid(False)\n",
    "sns.set(font_scale = 1.0)\n",
    "sns.set_style(\"ticks\")\n",
    "# Define colors for each category\n",
    "colors = {0: blue_rgb, 1: yellow_rgb}  # Adjust colors as needed\n",
    "\n",
    "markers = {\n",
    "    0: 'o',  # Circle\n",
    "    1: 's',  # Square\n",
    "    # Add more labels and markers as needed\n",
    "}\n",
    "\n",
    "for label, color in colors.items():\n",
    "    mask = (yvals == label)\n",
    "    #mask = (sample_yvals == label)\n",
    "    marker = markers[label]\n",
    "    plt.scatter(lv1_scores[mask], lv2_scores[mask], label=f'Label {label}', color=color,alpha=0.4,marker=marker)\n",
    "    #plt.scatter(sample_lv1_scores[mask], sample_lv2_scores[mask], label=f'Label {label}', color=color,alpha=0.4)\n",
    "    \n",
    "plt.xlabel('LV1 Scores (Xvar: 45.5%, Yvar: 9.9%)')\n",
    "plt.ylabel('LV2 Scores (Xvar: 72.32%,Yvar: >0.001%)')\n",
    "\n",
    "#accuracy = float(f\"{accuracy:.3f}\")\n",
    "plt.title('X Scores' + f\" (CV Accuracy: {average_accuracy:.2f}\"+', p<'+f\"0.001)\")\n",
    "\n",
    "# Create a legend\n",
    "pos_classifier = classifier[0]+'+'\n",
    "neg_classifier = classifier[0]+'-'\n",
    "legend_label = { f'{classifier[0]}-' : 0,  f'{classifier[0]}+' : 1 }\n",
    "legend_labels = [f'{label}' for label in legend_label]\n",
    "plt.legend(legend_labels)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.savefig(date + studyname + centerCell[0] + '_neighborPredictors.pdf', format='pdf',bbox_inches='tight')\n",
    "# Display the plot (optional)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd351a8-0f61-4c36-969f-c25c2e3d8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VIP scores\n",
    "def vip_efficient(model):\n",
    "    t = plsda.x_scores_\n",
    "    w = plsda.x_weights_ # replace with x_rotations_ if needed\n",
    "    q = plsda.y_loadings_\n",
    "    features_, _ = w.shape\n",
    "    vip = np.zeros(shape=(features_,))\n",
    "    inner_sum = np.diag(t.T @ t @ q.T @ q)\n",
    "    SS_total = np.sum(inner_sum)\n",
    "    vip = np.sqrt(features_*(w**2 @ inner_sum)/ SS_total)\n",
    "    return vip\n",
    "\n",
    "vips = vip_efficient(plsda)\n",
    "\n",
    "plt.figure(figsize=(2.5,5))\n",
    "\n",
    "sns.set(font_scale = 1.0)\n",
    "sns.set_style(\"ticks\")\n",
    "loadings_vips = pd.DataFrame(plsda.x_loadings_[:,0].flatten(), index= cellTypes, columns = ['loadings']) # what does this line mean \n",
    "loadings_vips['VIPs'] = vips\n",
    "loadings_vips['color'] = np.where(loadings_vips['loadings'] > 0, 'high', 'low')\n",
    "colors = {'high': yellow_rgb, 'low': blue_rgb}\n",
    "loadings_vips.index = loadings_vips.index.str.replace('_', ' ')\n",
    "loadings_vips = loadings_vips.sort_values(by = 'VIPs', ascending=False)\n",
    "for i in loadings_vips.index:\n",
    "    if loadings_vips.loc[i,'loadings'] < 0:\n",
    "        loadings_vips.loc[i,'VIPs'] = loadings_vips.loc[i,'VIPs']*-1\n",
    "sns.barplot(data = loadings_vips, x=loadings_vips['VIPs'],y = loadings_vips.index, hue = 'color', palette = colors)\n",
    "plt.axvline(x = -1, color = 'r', linestyle='--')\n",
    "plt.axvline(x = 1, color = 'r', linestyle='--')\n",
    "plt.legend().set_visible(False)\n",
    "plt.ylabel('')\n",
    "plt.title('VIPs for oPLSDA model')\n",
    "plt.savefig(date + studyname + centerCell[0] + '_VIPscores.pdf', format='pdf',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f20a5e-541a-4f04-b5b9-37f0a4ae7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set(font_scale=1.4)  # Adjust to fit the size of your confusion matrix\n",
    "sns.heatmap(cumulative_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Cumulative Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12994813-9a68-49c4-b84b-ba2523d6bbc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the .mat file\n",
    "mat_file_path = ''\n",
    "\n",
    "# Save the variables to a .mat file\n",
    "scipy.io.savemat(mat_file_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e632e-1d57-4cef-993c-d396c7267ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the path to the CSV file\n",
    "csv_file_path = ''\n",
    "\n",
    "# Read the CSV file intfo a DataFrame\n",
    "X_filt_loaded = pd.read_csv(csv_file_path, header=None).values\n",
    "print(X_filt_loaded.shape)\n",
    "X_filt_loaded = X_filt_loaded[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b695d4-5883-47b1-94cf-ead662f4e4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "# Define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# Calculate the size of each fold\n",
    "fold_size = len(X) // n_folds\n",
    "\n",
    "# Initialize variables to accumulate confusion matrix results and x_scores/y_scores\n",
    "cumulative_conf_matrix = [[0, 0], [0, 0]]\n",
    "cumulative_accuracy = 0\n",
    "cumulative_x_scores = []\n",
    "cumulative_y_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for i in range(n_folds):\n",
    "    # Determine the indices for this fold\n",
    "    start_idx = i * fold_size\n",
    "    end_idx = start_idx + fold_size\n",
    "\n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_test = X[start_idx:end_idx]\n",
    "    y_test = y[start_idx:end_idx]\n",
    "    X_train = np.concatenate([X[:start_idx], X[end_idx:]])\n",
    "    y_train = np.concatenate([y[:start_idx], y[end_idx:]])\n",
    "\n",
    "    # Create and fit the PLS-DA model\n",
    "    plsda = PLSRegression(n_components=2)\n",
    "    plsda.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = plsda.predict(X_test)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    y_pred_labels = [1 if p >= 0.2 else 0 for p in y_pred]\n",
    "\n",
    "    # Accumulate confusion matrix results\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
    "    cumulative_conf_matrix += conf_matrix\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "    cumulative_accuracy += accuracy\n",
    "\n",
    "    # Accumulate x_scores and y_scores\n",
    "    cumulative_x_scores.extend(plsda.x_scores_)\n",
    "    cumulative_y_scores.extend(plsda.y_scores_)\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "average_accuracy = cumulative_accuracy / n_folds\n",
    "\n",
    "# Calculate precision\n",
    "TP = cumulative_conf_matrix[1, 1]  # True Positives\n",
    "FP = cumulative_conf_matrix[0, 1]  # False Positives\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Cumulative Confusion Matrix:\\n{cumulative_conf_matrix}\")\n",
    "\n",
    "# Display the heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(cumulative_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Cumulative Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Optionally, you can also plot the cumulative x_scores and y_scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(cumulative_x_scores, cumulative_y_scores)\n",
    "plt.xlabel('X scores')\n",
    "plt.ylabel('Y scores')\n",
    "plt.title('Cumulative X scores vs Y scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536cbbb3-b685-475a-b956-3dbb69fd5655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### from imblearn.under_sampling import RandomUnderSampler\n",
    "sns.set\n",
    "# Combine lv1_scores, lv2_scores, and yvals into a DataFrame\n",
    "data = pd.DataFrame({'lv1_scores': lv1_scores, 'lv2_scores': lv2_scores, 'yvals': yvals})\n",
    "print(data)\n",
    "\n",
    "legend_labels = [f'{classifier[0]}-', f'{classifier[0]}+']\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data[['lv1_scores', 'lv2_scores']]\n",
    "y = data['yvals']\n",
    "\n",
    "# Instantiate the RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Resample the data\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Plot the resampled data\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define colors for each category\n",
    "colors = {0: 'blue', 1: 'orange'}  # Adjust colors as needed\n",
    "\n",
    "for label, color in colors.items():\n",
    "    mask = (y_resampled == label)\n",
    "    print(X_resampled[mask]['lv1_scores'])\n",
    "    plt.scatter(X_resampled[mask]['lv1_scores'], X_resampled[mask]['lv2_scores'], label=legend_labels[label], color=color, alpha=0.4)\n",
    "\n",
    "plt.xlabel('LV1 Scores')\n",
    "plt.ylabel('LV2 Scores')\n",
    "plt.title('Balanced PLS-DA Plot')\n",
    "\n",
    "# Create a legend\n",
    "plt.legend(title='Classification')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a22b6d-74a8-4886-b3ba-41cfdb639854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# PERFORMING PERMUTATION TESTING \n",
    "num_permutations = 1000\n",
    "permuted_accuracies = []\n",
    "permuted_aucs = np.zeros(num_permutations)\n",
    "plt.hist(y_pred, bins=10, label='y_pred', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of y_pred_permuted\n",
    "\n",
    "for i in range(num_permutations):\n",
    "    # Create a copy of the original target variable and then shuffle\n",
    "    y_permuted = shuffle(y_train, random_state=i)\n",
    "\n",
    "    # Ensure that X_train and y_permuted have the same order of samples\n",
    "    X_train_permuted = X_train.copy()  # No need to shuffle X_train\n",
    "\n",
    "    # Fit the model on permuted data\n",
    "    plsda_permuted = PLSRegression(n_components=2)\n",
    "    plsda_permuted.fit(X_train_permuted, y_permuted)\n",
    " \n",
    "    # Make predictions on the test set\n",
    "    y_pred_permuted = plsda_permuted.predict(X_test)\n",
    " \n",
    "    # Convert predictions to class labels\n",
    "    y_pred_labels_permuted = [1 if p >= 0.02 else 0 for p in y_pred_permuted]\n",
    "    print(sum(y_pred_labels_permuted))\n",
    "    # Calculate accuracy for the current permutation\n",
    "    accuracy_permuted = accuracy_score(y_test, y_pred_labels_permuted)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_permuted)\n",
    "\n",
    "# Calculate Area Under the ROC Curve (AUC-ROC)\n",
    "    permuted_auc = auc(fpr, tpr)\n",
    "    print(permuted_auc)\n",
    "    permuted_accuracies.append(accuracy_permuted)\n",
    "    permuted_aucs[i] = permuted_auc\n",
    "# Display permutation test results\n",
    "print(f\"Permutation Test Accuracies: {permuted_accuracies}\")\n",
    "auc_p_value = (np.sum(permuted_aucs >= roc_auc) + 1) / (num_permutations + 1)\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = np.sum(permuted_accuracies >= accuracy) / num_permutations\n",
    "print(f\"Accuracy P-value: {p_value}\")\n",
    "print(f\"AUC P-value: {auc_p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102adabc-65a0-4b89-9513-da559fd3a088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "# Assuming X and y are your feature matrix and target variable\n",
    "# Replace this with your actual data loading code\n",
    "X = xData[cellNeighbors]\n",
    "X = np.log1p(X)\n",
    "X_scaled = StandardScaler().fit_transform(X)  # Scale the predictors\n",
    "y = xData[classifier]\n",
    "#X_scaled = X_filt_loaded\n",
    "\n",
    "# Create the PLS-DA model\n",
    "plsda_model = PLSRegression(n_components=2)\n",
    "\n",
    "# Define a KFold object for 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "# Initialize an array to store accuracy scores\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the PLS-DA model on the training set\n",
    "    plsda_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = plsda_model.predict(X_test)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    y_pred_labels = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "    # Calculate accuracy for the current fold\n",
    "    accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# Display the cross-validated accuracy scores\n",
    "print(\"Cross-Validated Accuracy Scores:\", accuracy_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Standard Deviation of Accuracy:\", np.std(accuracy_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
